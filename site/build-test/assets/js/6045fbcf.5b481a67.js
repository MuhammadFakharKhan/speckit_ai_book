"use strict";(globalThis.webpackChunkfrontend_book=globalThis.webpackChunkfrontend_book||[]).push([[3391],{287(n,e,s){s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>t,toc:()=>d});var i=s(2540),a=s(3023);const r={title:"Simulated Sensors",sidebar_position:2,description:"Learn how to simulate various sensors in Gazebo and connect them to ROS 2 topics for humanoid robotics applications"},o="Simulated Sensors in Gazebo",t={id:"module2/simulated-sensors",title:"Simulated Sensors",description:"Learn how to simulate various sensors in Gazebo and connect them to ROS 2 topics for humanoid robotics applications",source:"@site/docs/module2/simulated-sensors.md",sourceDirName:"module2",slug:"/module2/simulated-sensors",permalink:"/docs/module2/simulated-sensors",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module2/simulated-sensors.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Simulated Sensors",sidebar_position:2,description:"Learn how to simulate various sensors in Gazebo and connect them to ROS 2 topics for humanoid robotics applications"},sidebar:"tutorialSidebar",previous:{title:"Gazebo Physics Simulation",permalink:"/docs/module2/gazebo-physics"},next:{title:"Unity Integration",permalink:"/docs/module2/unity-integration"}},l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Types of Sensors in Robotics",id:"types-of-sensors-in-robotics",level:2},{value:"Camera Sensors",id:"camera-sensors",level:3},{value:"LIDAR Sensors",id:"lidar-sensors",level:3},{value:"IMU Sensors",id:"imu-sensors",level:3},{value:"Configuring Sensors in Gazebo",id:"configuring-sensors-in-gazebo",level:2},{value:"Camera Sensor Configuration",id:"camera-sensor-configuration",level:3},{value:"LIDAR Sensor Configuration",id:"lidar-sensor-configuration",level:3},{value:"IMU Sensor Configuration",id:"imu-sensor-configuration",level:3},{value:"Connecting Sensors to ROS 2",id:"connecting-sensors-to-ros-2",level:2},{value:"Sensor Bridge Configuration",id:"sensor-bridge-configuration",level:3},{value:"Processing Sensor Data",id:"processing-sensor-data",level:2},{value:"Subscribing to Sensor Topics",id:"subscribing-to-sensor-topics",level:3},{value:"Sensor Validation and Quality Assurance",id:"sensor-validation-and-quality-assurance",level:2},{value:"Validating Sensor Data",id:"validating-sensor-data",level:3},{value:"Quality Metrics",id:"quality-metrics",level:3},{value:"Hands-on Example: Sensor Demo",id:"hands-on-example-sensor-demo",level:2},{value:"Sensor Integration Concepts",id:"sensor-integration-concepts",level:2},{value:"Sensor Data Publisher Implementation",id:"sensor-data-publisher-implementation",level:3},{value:"Sensor Validation Implementation",id:"sensor-validation-implementation",level:3},{value:"Object Detection with LIDAR",id:"object-detection-with-lidar",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"simulated-sensors-in-gazebo",children:"Simulated Sensors in Gazebo"}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Understand different types of sensors used in robotics"}),"\n",(0,i.jsx)(e.li,{children:"Configure camera, LIDAR, and IMU sensors in Gazebo"}),"\n",(0,i.jsx)(e.li,{children:"Connect simulated sensors to ROS 2 topics"}),"\n",(0,i.jsx)(e.li,{children:"Process and validate sensor data from simulation"}),"\n",(0,i.jsx)(e.li,{children:"Create sensor processing nodes for real-world applications"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(e.p,{children:"Sensors are crucial components of any robotic system, providing the robot with information about its environment and internal state. In simulation, we can create realistic sensor models that behave similarly to their real-world counterparts. This chapter will cover how to simulate common sensors in Gazebo and connect them to ROS 2 for processing and analysis."}),"\n",(0,i.jsx)(e.h2,{id:"types-of-sensors-in-robotics",children:"Types of Sensors in Robotics"}),"\n",(0,i.jsx)(e.h3,{id:"camera-sensors",children:"Camera Sensors"}),"\n",(0,i.jsx)(e.p,{children:"Camera sensors provide visual information about the environment. In Gazebo, camera sensors can be configured with various parameters:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Resolution"}),": Width and height in pixels"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Field of View (FOV)"}),": Angular extent of the scene captured"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Image Format"}),": Color depth and encoding"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Update Rate"}),": How frequently the camera publishes images"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"lidar-sensors",children:"LIDAR Sensors"}),"\n",(0,i.jsx)(e.p,{children:"LIDAR (Light Detection and Ranging) sensors measure distances by illuminating targets with laser light and measuring the reflection. In simulation:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Range"}),": Minimum and maximum detection distances"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Resolution"}),": Angular resolution of measurements"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Scan Pattern"}),": Horizontal and vertical field of view"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Update Rate"}),": Frequency of scans"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"imu-sensors",children:"IMU Sensors"}),"\n",(0,i.jsx)(e.p,{children:"Inertial Measurement Units (IMUs) measure angular velocity, linear acceleration, and sometimes magnetic field. In Gazebo:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Orientation"}),": 3D orientation of the sensor"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Angular Velocity"}),": Rotational velocity in 3D space"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Linear Acceleration"}),": Acceleration in 3D space"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Noise Models"}),": Realistic noise characteristics"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"configuring-sensors-in-gazebo",children:"Configuring Sensors in Gazebo"}),"\n",(0,i.jsx)(e.h3,{id:"camera-sensor-configuration",children:"Camera Sensor Configuration"}),"\n",(0,i.jsx)(e.p,{children:"Camera sensors in Gazebo are configured using SDF (Simulation Description Format). Here's a basic camera configuration:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\n  <camera name="head">\n    <horizontal_fov>1.047</horizontal_fov>\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>300</far>\n    </clip>\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.007</stddev>\n    </noise>\n  </camera>\n  <always_on>1</always_on>\n  <update_rate>30</update_rate>\n  <visualize>true</visualize>\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"lidar-sensor-configuration",children:"LIDAR Sensor Configuration"}),"\n",(0,i.jsx)(e.p,{children:"LIDAR sensors use ray-based simulation in Gazebo:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="lidar" type="ray">\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>360</samples>\n        <resolution>1</resolution>\n        <min_angle>-3.14159</min_angle>\n        <max_angle>3.14159</max_angle>\n      </horizontal>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>30.0</max>\n      <resolution>0.01</resolution>\n    </range>\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.01</stddev>\n    </noise>\n  </ray>\n  <always_on>1</always_on>\n  <update_rate>10</update_rate>\n  <visualize>true</visualize>\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"imu-sensor-configuration",children:"IMU Sensor Configuration"}),"\n",(0,i.jsx)(e.p,{children:"IMU sensors provide inertial measurements:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\n  <imu>\n    <angular_velocity>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.001</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.001</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.001</stddev>\n        </noise>\n      </z>\n    </angular_velocity>\n    <linear_acceleration>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n        </noise>\n      </z>\n    </linear_acceleration>\n  </imu>\n  <always_on>1</always_on>\n  <update_rate>100</update_rate>\n  <visualize>false</visualize>\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"connecting-sensors-to-ros-2",children:"Connecting Sensors to ROS 2"}),"\n",(0,i.jsx)(e.p,{children:"Gazebo can bridge sensor data to ROS 2 topics using the Gazebo ROS packages. The sensor bridge configuration maps Gazebo sensors to ROS 2 topics."}),"\n",(0,i.jsx)(e.h3,{id:"sensor-bridge-configuration",children:"Sensor Bridge Configuration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:'# ROS 2 to Gazebo Sensor Bridge Configuration\ncamera_bridge:\n  ros__parameters:\n    image_topic_name: "/camera/image_raw"\n    camera_info_topic_name: "/camera/camera_info"\n    camera_frame_id: "camera_link"\n    update_rate: 30.0\n\nlidar_bridge:\n  ros__parameters:\n    scan_topic_name: "/lidar/scan"\n    lidar_frame_id: "lidar_link"\n    update_rate: 10.0\n\nimu_bridge:\n  ros__parameters:\n    imu_topic_name: "/imu/data"\n    imu_frame_id: "imu_link"\n    update_rate: 100.0\n'})}),"\n",(0,i.jsx)(e.h2,{id:"processing-sensor-data",children:"Processing Sensor Data"}),"\n",(0,i.jsx)(e.h3,{id:"subscribing-to-sensor-topics",children:"Subscribing to Sensor Topics"}),"\n",(0,i.jsx)(e.p,{children:"In ROS 2, you can subscribe to sensor data using the appropriate message types:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, LaserScan, Imu\n\nclass SensorProcessor(Node):\n    def __init__(self):\n        super().__init__('sensor_processor')\n\n        # Create subscribers for different sensor types\n        self.camera_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.camera_callback,\n            10\n        )\n\n        self.lidar_sub = self.create_subscription(\n            LaserScan,\n            '/lidar/scan',\n            self.lidar_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Imu,\n            '/imu/data',\n            self.imu_callback,\n            10\n        )\n\n    def camera_callback(self, msg):\n        # Process camera image data\n        self.get_logger().info(f'Received image: {msg.width}x{msg.height}')\n\n    def lidar_callback(self, msg):\n        # Process LIDAR scan data\n        self.get_logger().info(f'Received scan with {len(msg.ranges)} ranges')\n\n    def imu_callback(self, msg):\n        # Process IMU data\n        self.get_logger().info(f'IMU orientation: {msg.orientation}')\n"})}),"\n",(0,i.jsx)(e.h2,{id:"sensor-validation-and-quality-assurance",children:"Sensor Validation and Quality Assurance"}),"\n",(0,i.jsx)(e.h3,{id:"validating-sensor-data",children:"Validating Sensor Data"}),"\n",(0,i.jsx)(e.p,{children:"It's important to validate that sensor data is of appropriate quality and format:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Timestamp validation"}),": Ensure messages have valid timestamps"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Range validation"}),": Check that sensor readings are within expected ranges"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Format validation"}),": Verify message structure and encoding"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Frequency validation"}),": Confirm sensors publish at expected rates"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"quality-metrics",children:"Quality Metrics"}),"\n",(0,i.jsx)(e.p,{children:"Common metrics for sensor validation include:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Data completeness"}),": Percentage of valid sensor readings"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Data accuracy"}),": How closely simulated data matches expected values"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Temporal consistency"}),": Regularity of sensor updates"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Spatial consistency"}),": Accuracy of spatial relationships in sensor data"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"hands-on-example-sensor-demo",children:"Hands-on Example: Sensor Demo"}),"\n",(0,i.jsx)(e.p,{children:"The following example demonstrates how to process and analyze sensor data from the simulated humanoid robot:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Example of sensor processing in simulation\nimport rclpy\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\n\nclass SensorDemo(Node):\n    def detect_objects(self, lidar_data):\n        """Simple object detection using LIDAR data."""\n        # Filter valid ranges\n        valid_ranges = [r for r in lidar_data.ranges\n                       if lidar_data.range_min <= r <= lidar_data.range_max]\n\n        if not valid_ranges:\n            return 0\n\n        # Simple clustering based on distance jumps\n        object_count = 0\n        for i in range(1, len(valid_ranges)):\n            if abs(valid_ranges[i] - valid_ranges[i-1]) > 0.5:\n                object_count += 1\n\n        return min(object_count, 10)  # Cap at 10 objects\n'})}),"\n",(0,i.jsx)(e.h2,{id:"sensor-integration-concepts",children:"Sensor Integration Concepts"}),"\n",(0,i.jsx)(e.h3,{id:"sensor-data-publisher-implementation",children:"Sensor Data Publisher Implementation"}),"\n",(0,i.jsx)(e.p,{children:"The sensor data publisher is responsible for converting Gazebo sensor data into ROS 2 messages. Here's a simplified implementation:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, LaserScan, Imu\n\nclass SensorPublisher(Node):\n    def __init__(self):\n        super().__init__('sensor_publisher')\n\n        # Create publishers for different sensor types\n        self.camera_pub = self.create_publisher(Image, '/camera/image_raw', 10)\n        self.lidar_pub = self.create_publisher(LaserScan, '/lidar/scan', 10)\n        self.imu_pub = self.create_publisher(Imu, '/imu/data', 10)\n\n        # Timer for publishing sensor data\n        self.timer = self.create_timer(0.1, self.publish_sensor_data)\n\n    def publish_sensor_data(self):\n        \"\"\"Publish sensor data to ROS topics.\"\"\"\n        # Implementation would convert Gazebo sensor data to ROS messages\n        pass\n"})}),"\n",(0,i.jsx)(e.h3,{id:"sensor-validation-implementation",children:"Sensor Validation Implementation"}),"\n",(0,i.jsx)(e.p,{children:"Sensor validation is crucial for ensuring data quality:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def validate_lidar_data(self, msg):\n    """Validate LIDAR scan data."""\n    errors = []\n\n    # Check if ranges are within expected bounds\n    invalid_ranges = [r for r in msg.ranges if r < msg.range_min or (r > msg.range_max and r != float(\'inf\'))]\n    if invalid_ranges:\n        errors.append(f"Out of range values: {len(invalid_ranges)} invalid ranges")\n\n    return len(errors) == 0, errors\n'})}),"\n",(0,i.jsx)(e.h3,{id:"object-detection-with-lidar",children:"Object Detection with LIDAR"}),"\n",(0,i.jsx)(e.p,{children:"Here's an example of processing LIDAR data for object detection:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def detect_objects(self, lidar_data):\n    """Simple object detection using LIDAR data."""\n    # Filter valid ranges\n    valid_ranges = [r for r in lidar_data.ranges\n                   if lidar_data.range_min <= r <= lidar_data.range_max]\n\n    if not valid_ranges:\n        return 0\n\n    # Simple clustering based on distance jumps\n    object_count = 0\n    for i in range(1, len(valid_ranges)):\n        if abs(valid_ranges[i] - valid_ranges[i-1]) > 0.5:  # Threshold for object boundary\n            object_count += 1\n\n    return min(object_count, 10)  # Cap at 10 objects\n'})}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"This chapter covered the fundamentals of simulating sensors in Gazebo and connecting them to ROS 2. You learned how to:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Configure different types of sensors in Gazebo"}),"\n",(0,i.jsx)(e.li,{children:"Connect sensors to ROS 2 topics using bridges"}),"\n",(0,i.jsx)(e.li,{children:"Process sensor data in ROS 2 nodes"}),"\n",(0,i.jsx)(e.li,{children:"Validate sensor data quality"}),"\n",(0,i.jsx)(e.li,{children:"Apply sensor data to practical applications"}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"The next chapter will explore how to integrate Unity for visualization and human-robot interaction, building upon the sensor simulation concepts you've learned here."}),"\n",(0,i.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Camera Calibration"}),": Simulate a camera with different focal lengths and observe the effect on the field of view."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"LIDAR Range Analysis"}),": Process LIDAR data to detect objects at different distances and sizes."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"IMU Integration"}),": Use IMU data to estimate robot orientation and movement patterns."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor Fusion"}),": Combine data from multiple sensors to improve environmental understanding."]}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}},3023(n,e,s){s.d(e,{R:()=>o,x:()=>t});var i=s(3696);const a={},r=i.createContext(a);function o(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);