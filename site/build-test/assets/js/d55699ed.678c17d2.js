"use strict";(globalThis.webpackChunkfrontend_book=globalThis.webpackChunkfrontend_book||[]).push([[7358],{3023(e,n,t){t.d(n,{R:()=>o,x:()=>r});var a=t(3696);const i={},s=a.createContext(i);function o(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:n},e.children)}},9388(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var a=t(2540),i=t(3023);const s={title:"Bipedal Navigation Concepts",description:"Navigation concepts specifically adapted for bipedal robots using Nav2, addressing unique challenges of humanoid locomotion",sidebar_position:4,tags:["navigation","bipedal","humanoid","nav2","locomotion"]},o="Bipedal Navigation Concepts",r={id:"nav2-humanoid/bipedal-navigation",title:"Bipedal Navigation Concepts",description:"Navigation concepts specifically adapted for bipedal robots using Nav2, addressing unique challenges of humanoid locomotion",source:"@site/docs/nav2-humanoid/bipedal-navigation.md",sourceDirName:"nav2-humanoid",slug:"/nav2-humanoid/bipedal-navigation",permalink:"/docs/nav2-humanoid/bipedal-navigation",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/nav2-humanoid/bipedal-navigation.md",tags:[{label:"navigation",permalink:"/docs/tags/navigation"},{label:"bipedal",permalink:"/docs/tags/bipedal"},{label:"humanoid",permalink:"/docs/tags/humanoid"},{label:"nav2",permalink:"/docs/tags/nav-2"},{label:"locomotion",permalink:"/docs/tags/locomotion"}],version:"current",sidebarPosition:4,frontMatter:{title:"Bipedal Navigation Concepts",description:"Navigation concepts specifically adapted for bipedal robots using Nav2, addressing unique challenges of humanoid locomotion",sidebar_position:4,tags:["navigation","bipedal","humanoid","nav2","locomotion"]},sidebar:"tutorialSidebar",previous:{title:"Localization for Humanoid Robots",permalink:"/docs/nav2-humanoid/localization"},next:{title:"Isaac Sim to Isaac ROS Integration",permalink:"/docs/isaac-sim-to-ros-integration"}},l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Fundamentals of Bipedal Navigation",id:"fundamentals-of-bipedal-navigation",level:2},{value:"Bipedal vs. Wheeled Navigation",id:"bipedal-vs-wheeled-navigation",level:3},{value:"Key Navigation Concepts",id:"key-navigation-concepts",level:3},{value:"Support Polygon and Balance",id:"support-polygon-and-balance",level:4},{value:"Step Planning and Execution",id:"step-planning-and-execution",level:4},{value:"Navigation Challenges for Humanoid Robots",id:"navigation-challenges-for-humanoid-robots",level:3},{value:"Environmental Challenges",id:"environmental-challenges",level:4},{value:"Dynamic Challenges",id:"dynamic-challenges",level:4},{value:"Bipedal-Specific Navigation Algorithms",id:"bipedal-specific-navigation-algorithms",level:2},{value:"Footstep Planning",id:"footstep-planning",level:3},{value:"Balance-Aware Path Planning",id:"balance-aware-path-planning",level:3},{value:"Nav2 Integration for Bipedal Navigation",id:"nav2-integration-for-bipedal-navigation",level:2},{value:"Custom Behavior Tree Nodes",id:"custom-behavior-tree-nodes",level:3},{value:"Behavior Tree Configuration",id:"behavior-tree-configuration",level:3},{value:"Gait Integration with Navigation",id:"gait-integration-with-navigation",level:2},{value:"Gait Pattern Selection",id:"gait-pattern-selection",level:3},{value:"Gait-Path Integration",id:"gait-path-integration",level:3},{value:"Safety and Recovery Behaviors",id:"safety-and-recovery-behaviors",level:2},{value:"Balance Recovery",id:"balance-recovery",level:3},{value:"Obstacle Avoidance for Bipedal Robots",id:"obstacle-avoidance-for-bipedal-robots",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Real-Time Requirements",id:"real-time-requirements",level:3},{value:"Computational Efficiency",id:"computational-efficiency",level:3},{value:"Integration with Perception Systems",id:"integration-with-perception-systems",level:2},{value:"Perception for Navigation",id:"perception-for-navigation",level:3},{value:"Multi-Sensor Fusion",id:"multi-sensor-fusion",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:2},{value:"Simulation Testing",id:"simulation-testing",level:3},{value:"Real Robot Testing",id:"real-robot-testing",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Debugging Strategies",id:"debugging-strategies",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Development Approach",id:"development-approach",level:3},{value:"Configuration Management",id:"configuration-management",level:3},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"bipedal-navigation-concepts",children:"Bipedal Navigation Concepts"}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsx)(n.p,{children:"Bipedal navigation for humanoid robots presents unique challenges that differ significantly from traditional wheeled robot navigation. This module covers the specific concepts, algorithms, and implementations required for effective navigation using bipedal locomotion with the Nav2 framework."}),"\n",(0,a.jsx)(n.h2,{id:"fundamentals-of-bipedal-navigation",children:"Fundamentals of Bipedal Navigation"}),"\n",(0,a.jsx)(n.h3,{id:"bipedal-vs-wheeled-navigation",children:"Bipedal vs. Wheeled Navigation"}),"\n",(0,a.jsx)(n.p,{children:"Bipedal navigation differs from wheeled navigation in several key ways:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Discrete step motion"}),": Movement occurs in discrete steps rather than continuous motion"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Balance requirements"}),": Robot must maintain balance throughout navigation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Three-dimensional movement"}),": Includes Z-axis movement for stairs, ramps, and elevation changes"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dynamic stability"}),": Stability changes with each step and body motion"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Step planning"}),": Requires planning of individual step locations"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"key-navigation-concepts",children:"Key Navigation Concepts"}),"\n",(0,a.jsx)(n.h4,{id:"support-polygon-and-balance",children:"Support Polygon and Balance"}),"\n",(0,a.jsx)(n.p,{children:"The support polygon is the area within which the robot's center of mass (CoM) must remain:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Single support"}),": When standing on one foot"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Double support"}),": When both feet are on the ground"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Stability margins"}),": Maintaining CoM within safe boundaries"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dynamic balance"}),": Managing balance during step transitions"]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"step-planning-and-execution",children:"Step Planning and Execution"}),"\n",(0,a.jsx)(n.p,{children:"Bipedal navigation requires careful step planning:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Footstep planning"}),": Determining where each foot should be placed"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Step timing"}),": Coordinating the timing of each step"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Step size limits"}),": Respecting maximum step size capabilities"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Gait patterns"}),": Following stable gait patterns during navigation"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"navigation-challenges-for-humanoid-robots",children:"Navigation Challenges for Humanoid Robots"}),"\n",(0,a.jsx)(n.h4,{id:"environmental-challenges",children:"Environmental Challenges"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Stairs and steps"}),": Navigating discrete elevation changes"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Ramps"}),": Handling inclined surfaces with proper gait"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Narrow passages"}),": Navigating spaces with limited width"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Uneven terrain"}),": Handling irregular surfaces and obstacles"]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"dynamic-challenges",children:"Dynamic Challenges"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Balance recovery"}),": Handling unexpected disturbances"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Obstacle avoidance"}),": Avoiding obstacles while maintaining balance"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dynamic obstacles"}),": Navigating around moving humans and objects"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Multi-level navigation"}),": Moving between different floor levels"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"bipedal-specific-navigation-algorithms",children:"Bipedal-Specific Navigation Algorithms"}),"\n",(0,a.jsx)(n.h3,{id:"footstep-planning",children:"Footstep Planning"}),"\n",(0,a.jsx)(n.p,{children:"Footstep planning is crucial for bipedal navigation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example footstep planning algorithm\nimport numpy as np\nfrom geometry_msgs.msg import Pose\nfrom nav_msgs.msg import Path\n\nclass FootstepPlanner:\n    def __init__(self):\n        self.max_step_length = 0.4  # meters\n        self.max_step_width = 0.2   # meters\n        self.max_step_height = 0.2  # meters\n        self.step_clearance = 0.05  # meters\n\n    def plan_footsteps(self, global_path, robot_pose):\n        """\n        Plan footstep sequence based on global path\n        """\n        footsteps = []\n\n        # Convert global path to step sequence\n        for i in range(len(global_path.poses) - 1):\n            start_pose = global_path.poses[i]\n            end_pose = global_path.poses[i + 1]\n\n            # Calculate steps between poses\n            steps = self.calculate_step_sequence(start_pose, end_pose)\n            footsteps.extend(steps)\n\n        return footsteps\n\n    def calculate_step_sequence(self, start_pose, end_pose):\n        """\n        Calculate sequence of footsteps between two poses\n        """\n        # Calculate distance and direction\n        dx = end_pose.position.x - start_pose.position.x\n        dy = end_pose.position.y - start_pose.position.y\n        distance = np.sqrt(dx**2 + dy**2)\n\n        # Calculate number of steps needed\n        num_steps = int(distance / self.max_step_length) + 1\n\n        footsteps = []\n        for i in range(num_steps):\n            ratio = (i + 1) / num_steps\n            step_x = start_pose.position.x + dx * ratio\n            step_y = start_pose.position.y + dy * ratio\n\n            # Create step pose\n            step_pose = Pose()\n            step_pose.position.x = step_x\n            step_pose.position.y = step_y\n            step_pose.position.z = start_pose.position.z  # Maintain height\n            step_pose.orientation = start_pose.orientation\n\n            footsteps.append(step_pose)\n\n        return footsteps\n\n    def validate_footstep(self, footstep_pose, costmap):\n        """\n        Validate if footstep is safe and stable\n        """\n        # Check if footstep is in collision-free area\n        grid_x, grid_y = self.world_to_map(footstep_pose.position.x, footstep_pose.position.y)\n\n        if not self.is_in_bounds(grid_x, grid_y, costmap):\n            return False\n\n        # Check cost at footstep location\n        cost = costmap.getCost(grid_x, grid_y)\n        if cost >= costmap.LETHAL_OBSTACLE:\n            return False\n\n        # Check for adequate support area\n        if not self.has_adequate_support(footstep_pose, costmap):\n            return False\n\n        return True\n'})}),"\n",(0,a.jsx)(n.h3,{id:"balance-aware-path-planning",children:"Balance-Aware Path Planning"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example balance-aware path planning\nclass BalanceAwarePlanner:\n    def __init__(self):\n        self.balance_margin = 0.1  # meters\n        self.max_lean_angle = 15.0  # degrees\n        self.com_height = 0.8  # center of mass height\n\n    def plan_balance_safe_path(self, start, goal, costmap):\n        """\n        Plan path considering balance constraints\n        """\n        # Use modified A* algorithm with balance constraints\n        open_set = [(0, start)]\n        came_from = {}\n        g_score = {start: 0}\n        f_score = {start: self.heuristic(start, goal)}\n\n        while open_set:\n            current = min(open_set, key=lambda x: x[0])[1]\n            open_set.remove((f_score.get(current, float(\'inf\')), current))\n\n            if current == goal:\n                return self.reconstruct_path(came_from, current)\n\n            for neighbor in self.get_neighbors(current, costmap):\n                # Check balance constraints before adding to path\n                if not self.is_balance_safe(current, neighbor):\n                    continue\n\n                tentative_g_score = g_score[current] + self.distance(current, neighbor)\n\n                if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g_score\n                    f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, goal)\n                    open_set.append((f_score[neighbor], neighbor))\n\n        return []  # No path found\n\n    def is_balance_safe(self, current_pose, next_pose):\n        """\n        Check if transition maintains balance\n        """\n        # Calculate lean angle based on step size and CoM height\n        dx = next_pose.position.x - current_pose.position.x\n        dy = next_pose.position.y - current_pose.position.y\n        step_distance = np.sqrt(dx**2 + dy**2)\n\n        # Calculate lean angle: tan(lean_angle) = step_distance / (2 * com_height)\n        lean_angle = np.arctan(step_distance / (2 * self.com_height)) * 180 / np.pi\n\n        return lean_angle <= self.max_lean_angle\n'})}),"\n",(0,a.jsx)(n.h2,{id:"nav2-integration-for-bipedal-navigation",children:"Nav2 Integration for Bipedal Navigation"}),"\n",(0,a.jsx)(n.h3,{id:"custom-behavior-tree-nodes",children:"Custom Behavior Tree Nodes"}),"\n",(0,a.jsx)(n.p,{children:"Create custom behavior tree nodes for humanoid navigation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Example custom BT node for step execution\nimport py_trees\nfrom geometry_msgs.msg import Pose\nfrom std_msgs.msg import Bool\n\nclass StepExecutionNode(py_trees.behaviour.Behaviour):\n    def __init__(self, name, step_pose):\n        super(StepExecutionNode, self).__init__(name)\n        self.step_pose = step_pose\n        self.step_publisher = None\n        self.balance_subscriber = None\n        self.balance_ok = True\n\n    def setup(self, **kwargs):\n        # Setup ROS publishers and subscribers\n        self.node = kwargs['node']\n        self.step_publisher = self.node.create_publisher(Pose, '/step_command', 10)\n        self.balance_subscriber = self.node.create_subscription(\n            Bool, '/balance_status', self.balance_callback, 10\n        )\n\n    def balance_callback(self, msg):\n        self.balance_ok = msg.data\n\n    def update(self):\n        if not self.balance_ok:\n            return py_trees.common.Status.FAILURE\n\n        # Execute the step\n        self.step_publisher.publish(self.step_pose)\n\n        # Wait for step completion\n        if self.is_step_complete():\n            return py_trees.common.Status.SUCCESS\n        else:\n            return py_trees.common.Status.RUNNING\n\n    def is_step_complete(self):\n        # Check if step execution is complete\n        # Implementation depends on robot's step completion detection\n        return True  # Simplified for example\n"})}),"\n",(0,a.jsx)(n.h3,{id:"behavior-tree-configuration",children:"Behavior Tree Configuration"}),"\n",(0,a.jsx)(n.p,{children:"Configure behavior tree for humanoid navigation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Example behavior tree for humanoid navigation --\x3e\n<root main_tree_to_execute="MainTree">\n    <BehaviorTree ID="MainTree">\n        <Sequence>\n            <GoalReached/>\n            <ComputePathToPose goal="{goal}" path="{path}"/>\n            <Fallback>\n                <RecoveryNode number_of_retries="2">\n                    <Sequence>\n                        <SmoothPath path="{path}" output="{smoothed_path}"/>\n                        <PlanFootsteps path="{smoothed_path}" footsteps="{footsteps}"/>\n                        <FollowFootsteps footsteps="{footsteps}"/>\n                    </Sequence>\n                    <ClearEntireCostmap name="ClearLocalCostmap" service_name="local_costmap/clear_entirely_local_costmap"/>\n                </RecoveryNode>\n                <ReactiveFallback>\n                    <CheckGoalReaching>\n                        <GoalReached goal="{goal}" tolerance="0.5"/>\n                    </CheckGoalReaching>\n                    <RecoveryNode number_of_retries="2">\n                        <Spin spin_dist="1.57"/>\n                        <Wait wait_duration="5"/>\n                    </RecoveryNode>\n                </ReactiveFallback>\n            </Fallback>\n        </Sequence>\n    </BehaviorTree>\n</root>\n'})}),"\n",(0,a.jsx)(n.h2,{id:"gait-integration-with-navigation",children:"Gait Integration with Navigation"}),"\n",(0,a.jsx)(n.h3,{id:"gait-pattern-selection",children:"Gait Pattern Selection"}),"\n",(0,a.jsx)(n.p,{children:"Select appropriate gait patterns for navigation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Static gait"}),": For careful, stable navigation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dynamic gait"}),": For faster movement when stability allows"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Adaptive gait"}),": Adjust gait based on terrain and obstacles"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Recovery gait"}),": Special patterns for balance recovery"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"gait-path-integration",children:"Gait-Path Integration"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example gait-path integration\nclass GaitPathIntegrator:\n    def __init__(self):\n        self.current_gait = "walking"\n        self.gait_parameters = {\n            "walking": {"step_length": 0.3, "step_height": 0.05, "step_timing": 0.8},\n            "careful": {"step_length": 0.2, "step_height": 0.03, "step_timing": 1.2},\n            "fast": {"step_length": 0.4, "step_height": 0.07, "step_timing": 0.6}\n        }\n\n    def select_gait_for_path_segment(self, path_segment, terrain_type):\n        """\n        Select appropriate gait based on path segment and terrain\n        """\n        if terrain_type == "rough":\n            return "careful"\n        elif terrain_type == "smooth" and self.is_safe_for_fast_navigation(path_segment):\n            return "fast"\n        else:\n            return "walking"\n\n    def adapt_path_to_gait(self, path, gait_type):\n        """\n        Adapt path to match gait characteristics\n        """\n        gait_params = self.gait_parameters[gait_type]\n        adapted_path = []\n\n        for i in range(len(path.poses)):\n            pose = path.poses[i]\n\n            # Adjust pose based on gait requirements\n            adjusted_pose = self.adjust_pose_for_gait(pose, gait_params)\n            adapted_path.append(adjusted_pose)\n\n        return adapted_path\n\n    def adjust_pose_for_gait(self, pose, gait_params):\n        """\n        Adjust pose to match gait requirements\n        """\n        adjusted_pose = Pose()\n        adjusted_pose.position = pose.position\n        adjusted_pose.orientation = pose.orientation\n\n        # Apply gait-specific adjustments\n        # This could include height adjustments, timing considerations, etc.\n\n        return adjusted_pose\n'})}),"\n",(0,a.jsx)(n.h2,{id:"safety-and-recovery-behaviors",children:"Safety and Recovery Behaviors"}),"\n",(0,a.jsx)(n.h3,{id:"balance-recovery",children:"Balance Recovery"}),"\n",(0,a.jsx)(n.p,{children:"Implement balance recovery behaviors:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example balance recovery system\nclass BalanceRecoverySystem:\n    def __init__(self):\n        self.balance_threshold = 0.2  # meters CoM deviation\n        self.recovery_step_size = 0.15  # meters\n        self.max_recovery_attempts = 3\n\n    def detect_balance_loss(self, com_position, support_polygon):\n        """\n        Detect if robot is losing balance\n        """\n        # Calculate distance from CoM to support polygon\n        distance_to_support = self.distance_to_polygon(com_position, support_polygon)\n\n        return distance_to_support > self.balance_threshold\n\n    def execute_balance_recovery(self, current_pose, target_com_position):\n        """\n        Execute balance recovery maneuver\n        """\n        recovery_steps = []\n\n        # Calculate recovery step to restore balance\n        recovery_direction = self.calculate_recovery_direction(\n            current_pose, target_com_position\n        )\n\n        # Generate recovery steps\n        recovery_step = self.generate_recovery_step(\n            current_pose, recovery_direction\n        )\n\n        recovery_steps.append(recovery_step)\n\n        return recovery_steps\n\n    def generate_recovery_step(self, current_pose, direction):\n        """\n        Generate a recovery step to restore balance\n        """\n        recovery_step = Pose()\n\n        # Calculate step position based on recovery direction\n        recovery_step.position.x = current_pose.position.x + direction.x * self.recovery_step_size\n        recovery_step.position.y = current_pose.position.y + direction.y * self.recovery_step_size\n        recovery_step.position.z = current_pose.position.z  # Maintain height\n\n        recovery_step.orientation = current_pose.orientation\n\n        return recovery_step\n'})}),"\n",(0,a.jsx)(n.h3,{id:"obstacle-avoidance-for-bipedal-robots",children:"Obstacle Avoidance for Bipedal Robots"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example bipedal-specific obstacle avoidance\nclass BipedalObstacleAvoider:\n    def __init__(self):\n        self.step_clearance = 0.1  # meters\n        self.min_passage_width = 0.4  # meters (typical humanoid shoulder width)\n        self.max_avoidance_distance = 2.0  # meters\n\n    def plan_around_obstacle(self, obstacle_pose, robot_pose, goal_pose):\n        """\n        Plan path around obstacle considering bipedal constraints\n        """\n        # Calculate obstacle width and determine if passable\n        if not self.is_passable_width(obstacle_pose):\n            return self.plan_alternative_path(obstacle_pose, robot_pose, goal_pose)\n\n        # Plan path around obstacle with adequate clearance\n        avoidance_path = self.calculate_avoidance_path(\n            obstacle_pose, robot_pose, goal_pose\n        )\n\n        # Validate path for bipedal navigation\n        if self.is_bipedal_valid_path(avoidance_path):\n            return avoidance_path\n        else:\n            return self.plan_alternative_path(obstacle_pose, robot_pose, goal_pose)\n\n    def is_passable_width(self, obstacle_pose):\n        """\n        Check if obstacle allows passage for humanoid robot\n        """\n        # Check if passage width is adequate for humanoid shoulders\n        return obstacle_pose.width >= self.min_passage_width\n\n    def calculate_avoidance_path(self, obstacle_pose, robot_pose, goal_pose):\n        """\n        Calculate path around obstacle\n        """\n        # Calculate avoidance points around obstacle\n        left_avoidance = self.calculate_left_avoidance_point(obstacle_pose)\n        right_avoidance = self.calculate_right_avoidance_point(obstacle_pose)\n\n        # Choose the better avoidance option\n        left_path = self.create_path(robot_pose, left_avoidance, goal_pose)\n        right_path = self.create_path(robot_pose, right_avoidance, goal_pose)\n\n        # Select path based on length and safety\n        if self.evaluate_path(left_path) >= self.evaluate_path(right_path):\n            return left_path\n        else:\n            return right_path\n\n    def evaluate_path(self, path):\n        """\n        Evaluate path for bipedal navigation suitability\n        """\n        # Consider path length, obstacle clearance, and balance requirements\n        length_score = 1.0 / len(path.poses)  # Shorter paths are better\n        clearance_score = self.calculate_clearance_score(path)\n        balance_score = self.calculate_balance_score(path)\n\n        return length_score * 0.3 + clearance_score * 0.4 + balance_score * 0.3\n'})}),"\n",(0,a.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,a.jsx)(n.h3,{id:"real-time-requirements",children:"Real-Time Requirements"}),"\n",(0,a.jsx)(n.p,{children:"Bipedal navigation has strict real-time requirements:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Step timing"}),": Steps must be executed within precise time windows"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Balance monitoring"}),": Balance must be checked continuously"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor processing"}),": Sensor data must be processed in real-time"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Path replanning"}),": Paths may need to be replanned quickly"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"computational-efficiency",children:"Computational Efficiency"}),"\n",(0,a.jsx)(n.p,{children:"Optimize algorithms for real-time performance:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example efficient path validation for bipedal robots\nclass EfficientPathValidator:\n    def __init__(self):\n        self.validation_cache = {}\n        self.cache_size_limit = 100\n\n    def is_path_valid_for_bipedal(self, path, costmap):\n        """\n        Efficiently validate path for bipedal navigation\n        """\n        # Create cache key for this path\n        path_key = self.create_path_key(path)\n\n        if path_key in self.validation_cache:\n            return self.validation_cache[path_key]\n\n        # Perform validation\n        is_valid = self.validate_path_internal(path, costmap)\n\n        # Store in cache\n        self.add_to_cache(path_key, is_valid)\n\n        return is_valid\n\n    def validate_path_internal(self, path, costmap):\n        """\n        Internal path validation with early termination\n        """\n        for pose in path.poses:\n            # Check if pose is valid\n            if not self.is_pose_valid_for_bipedal(pose, costmap):\n                return False\n\n        return True\n\n    def is_pose_valid_for_bipedal(self, pose, costmap):\n        """\n        Check if single pose is valid for bipedal navigation\n        """\n        # Convert to grid coordinates\n        grid_x, grid_y = self.world_to_map(pose.position.x, pose.position.y)\n\n        if not self.is_in_bounds(grid_x, grid_y, costmap):\n            return False\n\n        # Check cost at pose location\n        cost = costmap.getCost(grid_x, grid_y)\n        if cost >= costmap.LETHAL_OBSTACLE:\n            return False\n\n        # Check for adequate space around pose\n        if not self.has_adequate_space(pose, costmap):\n            return False\n\n        return True\n'})}),"\n",(0,a.jsx)(n.h2,{id:"integration-with-perception-systems",children:"Integration with Perception Systems"}),"\n",(0,a.jsx)(n.h3,{id:"perception-for-navigation",children:"Perception for Navigation"}),"\n",(0,a.jsx)(n.p,{children:"Integrate perception systems with navigation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Terrain classification"}),": Identify terrain types for gait selection"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Obstacle detection"}),": Detect obstacles for path planning"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Step height estimation"}),": Estimate step heights for safe navigation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Surface stability"}),": Assess surface stability for foot placement"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"multi-sensor-fusion",children:"Multi-Sensor Fusion"}),"\n",(0,a.jsx)(n.p,{children:"Combine multiple sensors for robust navigation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Example multi-sensor fusion for navigation\nclass NavigationSensorFusion:\n    def __init__(self):\n        self.lidar_processor = LidarProcessor()\n        self.camera_processor = CameraProcessor()\n        self.imu_processor = IMUProcessor()\n        self.fusion_filter = KalmanFilter()\n\n    def process_navigation_sensors(self):\n        """\n        Process data from multiple sensors for navigation\n        """\n        # Process individual sensor data\n        lidar_data = self.lidar_processor.get_processed_data()\n        camera_data = self.camera_processor.get_processed_data()\n        imu_data = self.imu_processor.get_processed_data()\n\n        # Fuse sensor data\n        fused_data = self.fusion_filter.fuse([lidar_data, camera_data, imu_data])\n\n        # Extract navigation-relevant information\n        obstacles = self.extract_obstacles(fused_data)\n        terrain_type = self.classify_terrain(fused_data)\n        robot_state = self.estimate_robot_state(fused_data)\n\n        return obstacles, terrain_type, robot_state\n'})}),"\n",(0,a.jsx)(n.h2,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,a.jsx)(n.h3,{id:"simulation-testing",children:"Simulation Testing"}),"\n",(0,a.jsx)(n.p,{children:"Test bipedal navigation in simulation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Gazebo simulation"}),": Test with realistic physics"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Isaac Sim"}),": Test with photorealistic rendering"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Various terrains"}),": Test on different surface types"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Obstacle scenarios"}),": Test with various obstacle configurations"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"real-robot-testing",children:"Real Robot Testing"}),"\n",(0,a.jsx)(n.p,{children:"Progress to real robot testing:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Controlled environments"}),": Start with simple, safe environments"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Gradual complexity"}),": Increase environment complexity gradually"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Safety measures"}),": Implement safety measures for testing"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance metrics"}),": Measure navigation success rate and efficiency"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,a.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Balance loss during navigation"}),": Implement better balance control"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Step execution failures"}),": Improve step execution reliability"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Path planning failures"}),": Enhance path planning with humanoid constraints"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor integration problems"}),": Debug sensor fusion and processing"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"debugging-strategies",children:"Debugging Strategies"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Visualization"}),": Use RViz to visualize planned paths and steps"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Logging"}),": Log navigation state and decisions for debugging"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Simulation"}),": Test fixes in simulation before real robot deployment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Gradual testing"}),": Test components individually before integration"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsx)(n.h3,{id:"development-approach",children:"Development Approach"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Simulation first"}),": Test navigation algorithms in simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Incremental development"}),": Add complexity gradually"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Safety first"}),": Always implement safety measures"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Validation"}),": Continuously validate with real-world tests"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"configuration-management",children:"Configuration Management"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Parameter tuning"}),": Carefully tune parameters for your specific robot"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Testing"}),": Test navigation in various environments"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Documentation"}),": Document all navigation configurations"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Fallback strategies"}),": Implement fallback navigation strategies"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.p,{children:["For more detailed information about Nav2 and bipedal navigation, refer to the ",(0,a.jsx)(n.a,{href:"https://navigation.ros.org/",children:"official Nav2 documentation"}),", research papers on humanoid navigation, and the ",(0,a.jsx)(n.a,{href:"https://navigation.ros.org/tutorials/",children:"ROS 2 Navigation tutorials"}),"."]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);